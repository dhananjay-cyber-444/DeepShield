!pip install gradio transformers timm datasets evaluate transformers accelerate evaluate torch torchvision matplotlib opencv-python scikit-learn --quiet
import torch
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import timm
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np
import os

import gradio as gr
from transformers import AutoImageProcessor, AutoModelForImageClassification
import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import io
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

#Dataset
# Upload kaggle.json
from google.colab import files
files.upload() 

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#Download the dataset (Kaggle dataset)
!kaggle datasets download -d manjilkarki/deepfake-and-real-images

# Unzip into dataset/ folder
!unzip -q deepfake-and-real-images.zip -d dataset

# ------------------------------
# Load Pretrained Deepfake Detector
# ------------------------------
MODEL_NAME = "dima806/deepfake_vs_real_image_detection"
processor = AutoImageProcessor.from_pretrained(MODEL_NAME)
model = AutoModelForImageClassification.from_pretrained(MODEL_NAME)
model.eval()

id2label = model.config.id2label

# ------------------------------
# Grad-CAM utility
# ------------------------------
def generate_gradcam(img, model, processor, target_class=None):
    """Generates Grad-CAM heatmap for an input image"""
    inputs = processor(images=img, return_tensors="pt")
    img_tensor = inputs["pixel_values"].requires_grad_(True)

    # Forward pass
    outputs = model(img_tensor)
    logits = outputs.logits
    if target_class is None:
        target_class = logits.argmax(dim=1).item()

    score = logits[:, target_class]
    score.backward()

    # Extract gradients and activations
    gradients = img_tensor.grad[0].mean(dim=[1, 2]).detach().numpy()
    activations = img_tensor[0].detach().numpy()

    # Weighted sum
    cam = np.zeros(activations.shape[1:], dtype=np.float32)
    for i, w in enumerate(gradients):
        cam += w * activations[i]

    cam = np.maximum(cam, 0)
    cam = cv2.resize(cam, (img.size[0], img.size[1]))
    cam = cam - cam.min()
    cam = cam / cam.max() if cam.max() != 0 else cam
    heatmap = (cam * 255).astype(np.uint8)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

    # Overlay heatmap on image
    img_np = np.array(img.convert("RGB"))
    overlay = cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)
    return Image.fromarray(overlay)

# ------------------------------
# Prediction Function
# ------------------------------
def predict(img):
    try:
        inputs = processor(images=img, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)

        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].numpy()
        results = {id2label[i]: float(probs[i]) for i in range(len(probs))}

        # Generate Grad-CAM overlay
        cam_img = generate_gradcam(img, model, processor, target_class=np.argmax(probs))

        return results, img, cam_img

    except Exception as e:
        return {"error": str(e)}, img, img

# -----------------
# Dataset Evaluation
# -----------------
from transformers import pipeline
from tqdm import tqdm

#Load model pipeline
classifier = pipeline(
    "image-classification",
    model=MODEL_NAME,
    device=device
)

dataset_root = "dataset/Dataset/" 

def evaluate_dataset(folder_path):
    y_true, y_pred = [], []

    for label in ["Real", "Fake"]:
        class_dir = os.path.join(folder_path, label)
        if not os.path.exists(class_dir):
            print(f"‚ö†Ô∏è Skipping {class_dir}, not found")
            continue

        for img_name in tqdm(os.listdir(class_dir), desc=f"Processing {label}"):
            img_path = os.path.join(class_dir, img_name)

            try:
                img = Image.open(img_path).convert("RGB")
                preds = classifier(img)
                pred_label = max(preds, key=lambda x: x["score"])["label"]

                y_true.append(label)
                y_pred.append(pred_label)

            except Exception as e:
                print(f"Error processing {img_path}: {e}")
                continue

    # Compute metrics
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, pos_label="Fake")
    rec = recall_score(y_true, y_pred, pos_label="Fake")
    f1 = f1_score(y_true, y_pred, pos_label="Fake")

    metrics = {
        "Accuracy": round(acc * 100, 2),
        "Precision": round(prec * 100, 2),
        "Recall": round(rec * 100, 2),
        "F1-score": round(f1 * 100, 2),
    }
    return metrics

# Example: test on validation dataset
test_folder = os.path.join(dataset_root, "Test")
results = evaluate_dataset(test_folder)

print("üìä Evaluation Results on Test Set:")
print(results)

# -----------------
# Gradio App
# -----------------
demo = gr.Interface(
    fn=predict,
    inputs=gr.Image(type="pil", label="Upload Face Image"),
    outputs=[
        gr.Label(num_top_classes=2, label="Prediction"),
        gr.Image(type="pil", label="Original Image"),
        gr.Image(type="pil", label="Grad-CAM Heatmap")
    ],
    title="üõ° DeepShield: Deepfake Detection Demo",
    description="Upload a face image. The model predicts Real vs Fake and shows manipulated regions using Grad-CAM.",
    examples=[
        ["https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cat.png"],
    ]
)

demo.launch()
